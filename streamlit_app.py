import streamlit as st
import json
import asyncio
import uuid
from operator import itemgetter
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain.memory import ConversationBufferMemory
import os
from utils.logging_config import get_logger
from dotenv import load_dotenv

load_dotenv()

# ë¡œê±° ì„¤ì •
logger = get_logger()

# ëª¨ë°”ì¼ ë·°í¬íŠ¸ ìµœì í™” CSS (dvh ë‹¨ìœ„ ì‚¬ìš©)
st.markdown("""
<style>
    /* ëª¨ë°”ì¼ ë·°í¬íŠ¸ ë†’ì´ ë™ì  ëŒ€ì‘ - dvh ë‹¨ìœ„ ì‚¬ìš© */
    .stApp {
        min-height: 100dvh !important;
    }
    
    /* ì±„íŒ… ì…ë ¥ ì˜ì—­ ëª¨ë°”ì¼ ìµœì í™” */
    .stChatFloatingInputContainer {
        bottom: env(safe-area-inset-bottom, 0px) !important;
        padding-bottom: max(env(safe-area-inset-bottom, 0px), 1rem) !important;
    }
    
    /* ëª¨ë°”ì¼ì—ì„œ í‚¤ë³´ë“œ ì˜¬ë¼ì˜¬ ë•Œ ë·°í¬íŠ¸ ë†’ì´ ì¡°ì • */
    @supports (height: 100dvh) {
        .stApp {
            height: 100dvh;
            min-height: 100dvh;
        }
    }
    
    /* CSS ë³€ìˆ˜ ì œê±° - config.toml í…Œë§ˆë§Œ ì‚¬ìš© */
    
    /* ëª¨ë°”ì¼ í™˜ê²½ ìµœì í™” - ì±„íŒ… ì…ë ¥ì°½ ìœ„ì¹˜ë§Œ ì¡°ì • */
    @media (max-width: 768px) {
        /* ì±„íŒ… ì…ë ¥ ì»¨í…Œì´ë„ˆ ìœ„ì¹˜ ì¡°ì • */
        .stElementContainer:has(.stChatInput) {
            position: fixed !important;
            bottom: 3rem !important;  /* í™”ë©´ í•˜ë‹¨ì—ì„œ 3rem(48px) ìœ„ë¡œ ì¡°ì • */
            left: 0.5rem !important;
            right: 0.5rem !important;
            z-index: 999 !important;
        }
        
        /* ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ í•˜ë‹¨ íŒ¨ë”© (ì±„íŒ… ì…ë ¥ì°½ ê³µê°„ í™•ë³´) */
        .main .block-container {
            padding-bottom: 6rem !important;
        }
    }
</style>
""", unsafe_allow_html=True)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ë¦¬ì¹˜ë£Œ ëŒ€í™” ì§€ì› ì—ì´ì „íŠ¸",
    page_icon="ğŸ¥¼",
    layout="centered",
    initial_sidebar_state="collapsed",
)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def load_participants():
    """ì°¸ê°€ì ì •ë³´ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(os.getenv("PARTICIPANTS_JSON_PATH"), 'r', encoding='utf-8') as f:
            participants = json.load(f).get("participants", {})
            logger.info(f"ì°¸ê°€ì ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(participants)}ëª…")
            return participants
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"ì°¸ê°€ì ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def load_prompt(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œì—ì„œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            logger.debug(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ: {file_path}")
            return content
    except FileNotFoundError as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}, ì˜¤ë¥˜: {e}")
        return "í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def authenticate_user(username: str, password: str) -> dict:
    """ì‚¬ìš©ì ì¸ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    participants = load_participants()
    logger.info(f"ë¡œê·¸ì¸ ì‹œë„: {username}")
    
    for user_id, user_data in participants.items():
        if user_data["username"] == username and user_data["password"] == password:
            logger.info(f"ë¡œê·¸ì¸ ì„±ê³µ: {user_id} ({user_data.get('name', 'Unknown')})")
            return {"user_id": user_id, "user_data": user_data}
    
    logger.warning(f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {username}")
    return None

def setup_model_and_chain(user_name: str, memory: ConversationBufferMemory):
    """OpenAI ëª¨ë¸ ë° ëŒ€í™” ì²´ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    
    # OpenAI ëª¨ë¸ ìƒì„± (ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)
    model = ChatOpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL_NAME"),
        temperature=0.5,
        streaming=True
    )
    
    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompt_template = load_prompt(os.getenv("THERAPY_SYSTEM_PROMPT_PATH"))
    system_prompt = system_prompt_template.replace("ê¸¸ë™ë‹˜", f"{user_name}ë‹˜")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ])
    
    # ì‹¤í–‰ ì²´ì¸ êµ¬ì„± (LangChain ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)
    runnable = (
        RunnablePassthrough.assign(
            history=RunnableLambda(memory.load_memory_variables) | itemgetter("history")
        )
        | prompt
        | model
        | StrOutputParser()
    )
    
    return runnable

def response_generator(runnable, question: str):
    """ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (LangChain ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)"""
    try:
        # LangChainì˜ ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš© (Streamlit í˜¸í™˜)
        for chunk in runnable.stream({"question": question}):
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if isinstance(chunk, dict) and "answer" in chunk:
                yield chunk["answer"]
            elif isinstance(chunk, str):
                yield chunk
            else:
                # ê¸°íƒ€ chunk í˜•íƒœ ì²˜ë¦¬
                yield str(chunk)
    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

async def async_response_generator(runnable, question: str):
    """ë¹„ë™ê¸° ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (LangChain astream ì‚¬ìš©)"""
    try:
        # LangChainì˜ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
        async for chunk in runnable.astream({"question": question}):
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if isinstance(chunk, dict) and "answer" in chunk:
                yield chunk["answer"]
            elif isinstance(chunk, str):
                yield chunk
            else:
                # ê¸°íƒ€ chunk í˜•íƒœ ì²˜ë¦¬
                yield str(chunk)
    except Exception as e:
        logger.error(f"ë¹„ë™ê¸° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        yield "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if "user_info" not in st.session_state:
    st.session_state.user_info = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = None
if "session_id" not in st.session_state:
    st.session_state.session_id = None
if "runnable" not in st.session_state:
    st.session_state.runnable = None

# --- ì¸ì¦ ì²˜ë¦¬ ---
if not st.session_state.authenticated:
    st.subheader("ğŸ” ë¡œê·¸ì¸")
    
    with st.form("login_form"):
        username = st.text_input("ì‚¬ìš©ìëª…")
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        login_button = st.form_submit_button("ë¡œê·¸ì¸")
        
        if login_button:
            if username and password:
                auth_result = authenticate_user(username, password)
                if auth_result:
                    st.session_state.authenticated = True
                    st.session_state.user_info = auth_result
                    
                    # ì„¸ì…˜ ID ìƒì„±
                    st.session_state.session_id = str(uuid.uuid4())
                    
                    # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
                    st.session_state.memory = ConversationBufferMemory(
                        memory_key="history", 
                        return_messages=True
                    )
                    
                    # ëª¨ë¸ ë° ì²´ì¸ ì„¤ì •
                    st.session_state.runnable = setup_model_and_chain(
                        auth_result["user_data"]["name"],
                        st.session_state.memory
                    )
                    
                    st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {auth_result['user_data']['name']}ë‹˜!")
                    st.rerun()
                else:
                    st.error("ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.error("ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

else:
    # --- ì¸ì¦ëœ ì‚¬ìš©ì ëŒ€í™” ì¸í„°í˜ì´ìŠ¤ ---
    user_name = st.session_state.user_info["user_data"]["name"]
    user_id = st.session_state.user_info["user_id"]
    
    # ì‚¬ì´ë“œë°”ì— ì‚¬ìš©ì ì •ë³´
    with st.sidebar:
        st.subheader("ğŸ‘¤ ì‚¬ìš©ì ì •ë³´")
        st.write(f"**ì´ë¦„:** {user_name}")
        
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            # ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬ (ê¸°ë³¸ ë©”ëª¨ë¦¬ì—ëŠ” close_session ì—†ìŒ)
            
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.authenticated = False
            st.session_state.user_info = None
            st.session_state.messages = []
            st.session_state.memory = None
            st.session_state.runnable = None
            st.session_state.session_id = None
            st.rerun()
    
    # ì‹œì‘ ë©”ì‹œì§€ ì´ˆê¸°í™” (ì²˜ìŒ ë¡œê·¸ì¸ ì‹œ)
    if not st.session_state.messages:
        start_message = f"{user_name}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ í•´ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
        st.session_state.messages.append({"role": "assistant", "content": start_message})
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ (Streamlit í‘œì¤€ ë°©ì‹)
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (Streamlit í‘œì¤€ ì±„íŒ… UI íŒ¨í„´)
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœ ë° ë©”ëª¨ë¦¬ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.memory.chat_memory.add_user_message(prompt)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ (Streamlit í‘œì¤€ ë°©ì‹)
        with st.chat_message("assistant"):
            response = st.write_stream(
                response_generator(st.session_state.runnable, prompt)
            )
            
            # ë¡œê¹…
            logger.info(f"AI ì‘ë‹µ ì™„ë£Œ: {user_id} - ì‚¬ìš©ì ë©”ì‹œì§€: {len(prompt)}ì, AI ì‘ë‹µ: {len(response)}ì")
        
        # AI ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœ ë° ë©”ëª¨ë¦¬ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.session_state.memory.chat_memory.add_ai_message(response)
    

